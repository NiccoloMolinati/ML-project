{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import load_dataset \n",
    "from PIL import Image\n",
    "import os, random\n",
    "import pandas as pd\n",
    "import transformers as tr\n",
    "import json\n",
    "import shutil\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id            img  label  \\\n",
      "0  42953  img/42953.png      0   \n",
      "\n",
      "                                               text  \n",
      "0  its their character not their color that matters  \n"
     ]
    }
   ],
   "source": [
    "# DO NOT RUN CELL!\n",
    "\n",
    "\"\"\"lines = []\n",
    "with open(\"hateful_memes/train.jsonl\") as f:\n",
    "    lines = f.read().splitlines()\n",
    "\n",
    "lines_dict = [json.loads(line) for line in lines]\n",
    "\n",
    "df = pd.DataFrame(lines_dict)\n",
    "print(df.loc[[0]])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files moved\n"
     ]
    }
   ],
   "source": [
    "# DO NOT RUN CELL!\n",
    "'''\n",
    "imgs_referenced = df[\"img\"]\n",
    "imgs_referenced.astype(str)\n",
    "\n",
    "def select_ref_imgs(orig_loc):\n",
    "    orig_loc = str(orig_loc)\n",
    "    file_name = orig_loc[4:]\n",
    "   \n",
    "    try:\n",
    "        shutil.move(f\".\\hateful_memes\\{orig_loc}\", f\".\\hateful_memes\\imgs_present/{file_name}\")\n",
    "        print(f\"file {file_name} moved\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"file {file_name} not found\")\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        print(f\"error:{e}\")\n",
    "\n",
    "def change_slash(string):\n",
    "    string = string.replace(\"/\",  \"\\ \" )\n",
    "    string = string.replace(\" \", \"\")\n",
    "    return string\n",
    "    '''\n",
    "\n",
    "# imgs_referenced = imgs_referenced.apply(change_slash)\n",
    "# imgs_referenced.apply(select_ref_imgs)\n",
    "\n",
    "print(\"files moved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files deleted\n"
     ]
    }
   ],
   "source": [
    "# DO NOT RUN CELL!\n",
    "\n",
    "# for file_name in os.listdir(\"./hateful_memes/img\"):\n",
    "    # file_path = os.path.join(\"./hateful_memes/img\", file_name)\n",
    "    # os.remove(file_path)\n",
    "    # print(f\"{file_path} deleted.\")\n",
    "    # pass\n",
    "print (\"files deleted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN CELL!\n",
    "\n",
    "# shutil.rmtree(\"hateful_memes/img_old\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN CELL!\n",
    "\n",
    "# os.rename(\"hateful_memes/imgs_present\", \"hateful_memes/img\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files present\n"
     ]
    }
   ],
   "source": [
    "# DO NOT RUN CELL!\n",
    "\n",
    "\"\"\"def check_imgs_exist(file_path):\n",
    "    file_path = str(file_path)\n",
    "    file_name = file_path[4:]\n",
    "    if os.path.isfile(f\"hateful_memes/{file_path}\"):\n",
    "        # print(f\"{file_name} present\")\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "reference_df = df\n",
    "reference_df[\"img_exists\"] = reference_df[\"img\"].apply(check_imgs_exist)\n",
    "reference_df = reference_df[reference_df[\"img_exists\"]]\n",
    "reference_df = reference_df.drop(columns=[\"img_exists\"])\n",
    "reference_df = reference_df.reset_index()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index     id            img  label  \\\n",
      "0      0  42953  img/42953.png      0   \n",
      "1      2  13894  img/13894.png      0   \n",
      "2      4  82403  img/82403.png      0   \n",
      "3      5  16952  img/16952.png      0   \n",
      "4      6  76932  img/76932.png      0   \n",
      "\n",
      "                                                text  \n",
      "0   its their character not their color that matters  \n",
      "1                           putting bows on your pet  \n",
      "2  everybody loves chocolate chip cookies, even h...  \n",
      "3           go sports! do the thing! win the points!  \n",
      "4     fine you're right. now can we fucking drop it?   6744\n"
     ]
    }
   ],
   "source": [
    "# DO NOT RUN CELL!\n",
    "\n",
    "# print(reference_df.head(), len(reference_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     index     id            img  label  \\\n",
      "882   1112  14507  img/14507.png      1   \n",
      "\n",
      "                                                  text  \n",
      "882  when your history teacher starts talking about...  \n"
     ]
    }
   ],
   "source": [
    "# DO NOT RUN CELL!\n",
    "\n",
    "# print(reference_df.query(\"id == '14507'\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN CELL!\n",
    "\n",
    "# reference_df = reference_df.astype({\"index\":int, \"id\":int, \"img\":str, \"label\":float, \"text\":str})\n",
    "# data = reference_df\n",
    "\n",
    "# data.to_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  index     id            img  label  \\\n",
      "0           0      0  42953  img/42953.png    0.0   \n",
      "1           1      2  13894  img/13894.png    0.0   \n",
      "2           2      4  82403  img/82403.png    0.0   \n",
      "3           3      5  16952  img/16952.png    0.0   \n",
      "4           4      6  76932  img/76932.png    0.0   \n",
      "\n",
      "                                                text  \n",
      "0   its their character not their color that matters  \n",
      "1                           putting bows on your pet  \n",
      "2  everybody loves chocolate chip cookies, even h...  \n",
      "3           go sports! do the thing! win the points!  \n",
      "4     fine you're right. now can we fucking drop it?  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"data.csv\")\n",
    "print (data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetTxt (Dataset):\n",
    "    def __init__(self, df, tokenizer):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        self.text= df[\"text\"].values\n",
    "        self.label = df[\"label\"].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df[\"label\"])\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        text = self.text[index]\n",
    "        label = self.label[index]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(text, add_special_tokens=True, return_token_type_ids=False,\n",
    "            padding='longest', return_attention_mask=True, return_tensors='pt', truncation=True)\n",
    "\n",
    "        return {\"input_ids\": encoding[\"input_ids\"].flatten(), \"attention_mask\": encoding[\"attention_mask\"].flatten(),\n",
    "                \"labels\": t.tensor(label, dtype=t.long)}\n",
    "        \n",
    "class DatasetImg (Dataset):\n",
    "    def __init__(self, df, img_dir):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transforms.Compose([\n",
    "                    transforms.Resize((224, 224)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "                    ])\n",
    "\n",
    "        self.img= df[\"img\"].values\n",
    "        self.label = df[\"label\"].astype(int).values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df[\"label\"])\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img_pth = os.path.join(self.img_dir, self.img[index])\n",
    "        img = Image.open(img_pth).convert(\"RGB\")\n",
    "        img_tensor = self.transform(img).unsqueeze(0)\n",
    "        img_tensor = img_tensor.squeeze(1)\n",
    "        label = self.label[index]\n",
    "\n",
    "        return img_tensor, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data 50%\n",
    "train_data, rest = train_test_split(data, test_size= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tr.BertTokenizer.from_pretrained(\"Hate-speech-CNERG/dehatebert-mono-english\", clean_up_tokenization_spaces=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_ds = DatasetTxt(train_data, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "imag_ds = DatasetImg(train_data, img_dir=\"hateful_memes/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_collator = tr.DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_txt = DataLoader(text_ds, batch_size=16, shuffle=True, collate_fn=d_collator)\n",
    "train_loader_img = DataLoader(imag_ds, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MonoLateFusModel(nn.Module):\n",
    "    def __init__(self, text_model, img_model, text_dims, img_dims):\n",
    "        super().__init__()\n",
    "        self.text_model = text_model\n",
    "        self.img_model = img_model\n",
    "\n",
    "\n",
    "        # architecture\n",
    "        #ToxicBERT/HateBERT input\n",
    "        self.textfc = nn.Linear(text_dims, 128)\n",
    "        #ResNet input\n",
    "        self.imgfc = nn.Linear(img_dims, 128)\n",
    "        self.mlp = nn.Sequential(nn.Linear(128, 16), nn.ReLU(), nn.Linear(16, 2))\n",
    "\n",
    "    def forward(self, tokenized_text, image):\n",
    "        #to be done\n",
    "        cloned_txt_model =copy.deepcopy(self.text_model)\n",
    "        cloned_img_model = copy.deepcopy(self.img_model)\n",
    "        \n",
    "        toktext = tokenized_text[\"input_ids\"]\n",
    "        mask = tokenized_text[\"attention_mask\"]\n",
    "        labels = tokenized_text[\"labels\"]\n",
    "\n",
    "        # txt_proc = self.textfc(self.text_model(tokenized_text))\n",
    "        # img_proc = self.imgfc(self.img_model(image))\n",
    "\n",
    "        logits_for_txt = cloned_txt_model(input_ids=toktext, attention_mask=mask, labels=labels).logits\n",
    "        img_t = cloned_img_model(image)\n",
    "\n",
    "        txt_proc = self.textfc(logits_for_txt)\n",
    "        img_proc = self.imgfc(img_t)\n",
    "\n",
    "        txt_fft = t.fft.fft(txt_proc)\n",
    "        img_fft = t.fft.fft(img_proc)\n",
    "\n",
    "        fusion = t.real(txt_fft * img_fft)\n",
    "        logits = self.mlp(fusion)\n",
    "\n",
    "        # print(\"image: \", img_t)\n",
    "        # print(\"text output: \", logits_for_txt)\n",
    "        #print(\"Text proc output:\", txt_proc)\n",
    "        #print(\"Image proc output:\", img_proc)\n",
    "        #print(\"Txt FFT:\", txt_fft)\n",
    "        #print(\"Img FFT:\", img_fft)\n",
    "        #print(\"Fusion output:\", fusion)\n",
    "        # combined_outputs = t.cat([txt_proc, img_proc], 1)\n",
    "        # outputs = self.fusion(combined_outputs)\n",
    "\n",
    "        return logits\n",
    "    \n",
    "    def fine_tune_subpart(self, dataloader, input_type):\n",
    "        model = self.text_model if input_type == \"txt\" else self.img_model\n",
    "        model.train()\n",
    "\n",
    "\n",
    "        tot_loss = 0\n",
    "        correct_preds = 0\n",
    "        #tot_val = 0\n",
    "\n",
    "        if input_type == \"txt\":\n",
    "            for name, param in model.named_parameters():\n",
    "                if \"classifier\" not in name:\n",
    "                    param.requires_grad = False\n",
    "            optimizer_txt = optim.AdamW(model.parameters(), lr= 5e-5)\n",
    "            scheduler = optim.lr_scheduler.StepLR(optimizer_txt, step_size=1, gamma=0.9)\n",
    "            \n",
    "        elif input_type == \"img\":\n",
    "            for name, param in model.named_parameters():\n",
    "                if \"fc\" not in name:\n",
    "                    param.requires_grad = False\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer_img = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "\n",
    "        for e in range(3):\n",
    "            if input_type == \"txt\":\n",
    "                for batch in dataloader:\n",
    "                    toktext = batch[\"input_ids\"]\n",
    "                    mask = batch[\"attention_mask\"]\n",
    "                    labels = batch[\"labels\"]\n",
    "\n",
    "\n",
    "                    outputs = model(input_ids=toktext, attention_mask=mask, labels=labels)\n",
    "\n",
    "                    # loss= nn.CrossEntropyLoss()\n",
    "\n",
    "                    loss = outputs.loss\n",
    "                    logits = outputs.logits\n",
    "\n",
    "                    optimizer_txt.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer_txt.step()\n",
    "                    scheduler.step()\n",
    "                    tot_loss += loss.item()\n",
    "\n",
    "                    pred = t.argmax(logits, -1)\n",
    "                print(f\"LOSS: {loss.item()}, PRED: {pred}\")\n",
    "                    \n",
    "\n",
    "            elif input_type == \"img\":\n",
    "                for images, labels in dataloader:\n",
    "\n",
    "                    images = images.squeeze(1)\n",
    "\n",
    "                    optimizer_img.zero_grad()\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs.float(), labels)\n",
    "                    loss.backward()\n",
    "                    optimizer_img.step()\n",
    "                    tot_loss += loss.item()\n",
    "                    \n",
    "                    #tot_val += labels.size(0)\n",
    "                    \n",
    "                    _, pred = t.max(outputs.data, 1)\n",
    "                print(f\"LOSS: {loss.item()}, PRED: {pred}\")\n",
    "\n",
    "            \n",
    "            else:\n",
    "                print (\"input_type must be either 'txt' or 'img'\")\n",
    "                \n",
    "            correct_preds = t.sum(pred == labels)\n",
    "            print(f\"batch {e+1}/3\", \n",
    "                  f\"loss: {tot_loss/(len(dataloader)*(e+1)):.4f}, accuracy: {100*(correct_preds/(len(dataloader))):.4f}\")\n",
    "        return \"loss:\", tot_loss/(len(dataloader)*(e+1)), \"accuracy:\", 100*(correct_preds/(len(dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_txt = tr.AutoModelForSequenceClassification.from_pretrained(\"Hate-speech-CNERG/dehatebert-mono-english\", num_labels = 2)\n",
    "model_img = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmc_lf_model = MonoLateFusModel(text_model=model_txt, img_model=model_img, text_dims=2, img_dims=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 1.0692874193191528, PRED: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "batch 1/3 loss: 0.7106, accuracy: 3.3175\n",
      "LOSS: 0.6430527567863464, PRED: tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "batch 2/3 loss: 0.7130, accuracy: 4.2654\n",
      "LOSS: 0.8184334635734558, PRED: tensor([0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0])\n",
      "batch 3/3 loss: 0.7149, accuracy: 3.3175\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('loss:', 0.7148623623271689, 'accuracy:', tensor(3.3175))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmc_lf_model.fine_tune_subpart(train_loader_txt, \"txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS: 0.8351051211357117, PRED: tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0])\n",
      "batch 1/3 loss: 1.2329, accuracy: 3.7915\n",
      "LOSS: 0.7963578104972839, PRED: tensor([1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0])\n",
      "batch 2/3 loss: 0.9827, accuracy: 3.3175\n",
      "LOSS: 0.5978100895881653, PRED: tensor([0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0])\n",
      "batch 3/3 loss: 0.8787, accuracy: 4.2654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('loss:', 0.8786777587486858, 'accuracy:', tensor(4.2654))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmc_lf_model.fine_tune_subpart(train_loader_img, \"img\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset_hmc (Dataset):\n",
    "    def __init__(self, df, tokenizer, img_path):\n",
    "        super().__init__()\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.img_dir = img_path\n",
    "        self.transform = transforms.Compose([\n",
    "                    transforms.Resize((224, 224)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "                    ])\n",
    "\n",
    "        self.text= df[\"text\"].values\n",
    "        self.label = df[\"label\"].values\n",
    "        self.img = df[\"img\"].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df[\"label\"])\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        text = self.text[index]\n",
    "        label = self.label[index]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(text, add_special_tokens=True, return_token_type_ids=False,\n",
    "            padding='longest', return_attention_mask=True, return_tensors='pt', truncation=True)\n",
    "        \n",
    "        img_pth = os.path.join(self.img_dir, self.img[index])\n",
    "        img = Image.open(img_pth).convert(\"RGB\")\n",
    "        img_tensor = self.transform(img).unsqueeze(0)\n",
    "        img_tensor = img_tensor.squeeze(1)\n",
    "        label = self.label[index]\n",
    "\n",
    "        return {\"input_ids\": encoding[\"input_ids\"].flatten(), \n",
    "                \"attention_mask\": encoding[\"attention_mask\"].flatten(),\n",
    "                \"img_tensor\": img_tensor,\n",
    "                \"labels\": t.tensor(label, dtype=t.long),\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hmc, test = train_test_split(rest, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_hmc = dataset_hmc(df=train_hmc, tokenizer=tokenizer, img_path=\"hateful_memes/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_hmc = DataLoader(ds_hmc, batch_size=16, shuffle=True, collate_fn=d_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1/3 loss: 7.3669, accuracy: 9.5203\n",
      "batch 2/3 loss: 6.9181, accuracy: 18.7297\n",
      "batch 3/3 loss: 6.3881, accuracy: 28.1824\n"
     ]
    }
   ],
   "source": [
    "hmc_lf_model.img_model.train()\n",
    "for name, param in hmc_lf_model.img_model.named_parameters():\n",
    "    if \"fc\" not in name:\n",
    "        param.requires_grad = False\n",
    "    if not param.requires_grad and param.grad is not None:\n",
    "        print(f\"Warning: {name} has a gradient despite being frozen.\")\n",
    "    #print(f\"{name}: requires_grad={param.requires_grad}\")\n",
    "hmc_lf_model.text_model.train()\n",
    "for name, param in hmc_lf_model.text_model.named_parameters():\n",
    "    if \"classifier\" not in name:\n",
    "        param.requires_grad = False\n",
    "    if not param.requires_grad and param.grad is not None:\n",
    "        print(f\"Warning: {name} has a gradient despite being frozen.\")\n",
    "    # print(f\"{name}: requires_grad={param.requires_grad}\")\n",
    "\n",
    "for name, param in hmc_lf_model.named_parameters():\n",
    "    if not param.requires_grad and param.grad is not None:\n",
    "        print(f\"Warning: {name} has a gradient despite being frozen.\")\n",
    "    #print(f\"{name}: requires_grad={param.requires_grad}\")\n",
    "\n",
    "hmc_lf_model.train()\n",
    "\n",
    "\n",
    "total_loss = 0\n",
    "correct_preds = 0\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer_general = t.optim.AdamW(filter(lambda p: p.requires_grad, hmc_lf_model.parameters()), \n",
    "    lr=1e-5\n",
    ")\n",
    "# optimizer_img = optim.Adam(hmc_lf_model.img_model.fc.parameters(), lr=0.001)\n",
    "# optimizer_txt = optim.AdamW(hmc_lf_model.text_model.parameters(), lr= 5e-5)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer_txt, step_size=1, gamma=0.9)\n",
    "\n",
    "for e in range(3):\n",
    "    for batch in dataloader_hmc:\n",
    "        \n",
    "        text_data = {\n",
    "        \"input_ids\": batch[\"input_ids\"],\n",
    "        \"attention_mask\": batch[\"attention_mask\"],\n",
    "        \"labels\": batch[\"labels\"]\n",
    "        }\n",
    "        img = batch[\"img_tensor\"]\n",
    "        img_squeezed = img.squeeze(1)\n",
    "        label = batch[\"labels\"]\n",
    "        # print(text_data)\n",
    "\n",
    "        outputs = hmc_lf_model(text_data,img_squeezed)\n",
    "        #print (outputs)\n",
    "        loss = loss_function(outputs, label)\n",
    "\n",
    "        optimizer_general.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer_general.step()\n",
    "        #print(f\"loss: {loss.item()}\")\n",
    "        total_loss += loss.item()\n",
    "        _, pred = t.max(outputs.data, 1)\n",
    "\n",
    "        correct_preds += t.sum(pred == label)\n",
    "\n",
    "    print(f\"batch {e+1}/3\", \n",
    "    f\"loss: {total_loss/(len(dataloader_hmc)*(e+1)):.4f}, accuracy: {correct_preds.float()/len(dataloader_hmc):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ex5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
